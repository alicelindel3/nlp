{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/alicelindel3/nlp/blob/main/Section_10/learn_dialogue.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W-SnrPOgQgRR"
      },
      "source": [
        "# 対話の学習\n",
        "宮沢賢治の小説において、次の文章を予測できるようにSeq2Seqのモデルを訓練します。  \n",
        "これにより、賢治風の返答が生成できるようになります。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "85B-RAV9QgRh"
      },
      "source": [
        "## 使用する文字\n",
        "学習をなるべく簡単にするために、ひらがなとカタカナ、記号のみを使用します。  \n",
        "コーパスで使われていない文字の入力にも対応するために、全てのひらがなとカタカナを用意します。  \n",
        "また、それ以外の記号などについては、コーパスで使われているものを加えます。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "LeneeKcoQgRj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8fae0b8a-6405-428b-ca6b-95156923e222"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['\\t', '\\n', '、', '。', '々', 'ぁ', 'あ', 'ぃ', 'い', 'ぅ', 'う', 'ぇ', 'え', 'ぉ', 'お', 'か', 'が', 'き', 'ぎ', 'く', 'ぐ', 'け', 'げ', 'こ', 'ご', 'さ', 'ざ', 'し', 'じ', 'す', 'ず', 'せ', 'ぜ', 'そ', 'ぞ', 'た', 'だ', 'ち', 'ぢ', 'っ', 'つ', 'づ', 'て', 'で', 'と', 'ど', 'な', 'に', 'ぬ', 'ね', 'の', 'は', 'ば', 'ぱ', 'ひ', 'び', 'ぴ', 'ふ', 'ぶ', 'ぷ', 'へ', 'べ', 'ぺ', 'ほ', 'ぼ', 'ぽ', 'ま', 'み', 'む', 'め', 'も', 'ゃ', 'や', 'ゅ', 'ゆ', 'ょ', 'よ', 'ら', 'り', 'る', 'れ', 'ろ', 'ゎ', 'わ', 'ゐ', 'ゑ', 'を', 'ん', 'ァ', 'ア', 'ィ', 'イ', 'ゥ', 'ウ', 'ェ', 'エ', 'ォ', 'オ', 'カ', 'ガ', 'キ', 'ギ', 'ク', 'グ', 'ケ', 'ゲ', 'コ', 'ゴ', 'サ', 'ザ', 'シ', 'ジ', 'ス', 'ズ', 'セ', 'ゼ', 'ソ', 'ゾ', 'タ', 'ダ', 'チ', 'ヂ', 'ッ', 'ツ', 'ヅ', 'テ', 'デ', 'ト', 'ド', 'ナ', 'ニ', 'ヌ', 'ネ', 'ノ', 'ハ', 'バ', 'パ', 'ヒ', 'ビ', 'ピ', 'フ', 'ブ', 'プ', 'ヘ', 'ベ', 'ペ', 'ホ', 'ボ', 'ポ', 'マ', 'ミ', 'ム', 'メ', 'モ', 'ャ', 'ヤ', 'ュ', 'ユ', 'ョ', 'ヨ', 'ラ', 'リ', 'ル', 'レ', 'ロ', 'ヮ', 'ワ', 'ヰ', 'ヱ', 'ヲ', 'ン', 'ヴ', '・', 'ー', '？']\n"
          ]
        }
      ],
      "source": [
        "import pickle\n",
        "\n",
        "hiragana = \"ぁあぃいぅうぇえぉおかがきぎくぐけげこごさざしじすずせぜそぞ\\\n",
        "ただちぢっつづてでとどなにぬねのはばぱひびぴふぶぷへべぺほぼぽ\\\n",
        "まみむめもゃやゅゆょよらりるれろゎわゐゑをん\"\n",
        "\n",
        "katakana = \"ァアィイゥウェエォオカガキギクグケゲコゴサザシジスズセゼソゾ\\\n",
        "タダチヂッツヅテデトドナニヌネノハバパヒビピフブプヘベペホボポ\\\n",
        "マミムメモャヤュユョヨラリルレロヮワヰヱヲンヴ\"\n",
        "\n",
        "chars = hiragana + katakana\n",
        "\n",
        "with open(\"kana_kenji.txt\", mode=\"r\", encoding=\"utf-8\") as f:  # 前回保存したファイル\n",
        "    text = f.read()\n",
        "    \n",
        "for char in text:  # ひらがな、カタカナ以外でコーパスに使われている文字を追加\n",
        "    if char not in chars:\n",
        "        chars += char\n",
        "        \n",
        "chars += \"\\t\\n\"  # タブと改行を追加\n",
        "        \n",
        "chars_list = sorted(list(chars))  # 文字列をリストに変換してソートする\n",
        "print(chars_list)\n",
        "\n",
        "with open(\"kana_chars.pickle\", mode=\"wb\") as f:  # pickleで保存\n",
        "    pickle.dump(chars_list, f)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rHGAjwMDQgRp"
      },
      "source": [
        "## 文字のベクトル化\n",
        "各文字をone-hot表現で表し、encoderへの入力、decoderへの入力、decoderの正解を作成します。  \n",
        "各文章はそれぞれ長さが違いますが、文章の終了後は全て0のベクトルで埋めます。  \n",
        "学習効率を考慮し、長すぎる文章はカットします。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "iZI6lFGsQgRq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a73de6c7-278c-46f9-f3e3-980fffb00467"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:30: DeprecationWarning: `np.bool` is a deprecated alias for the builtin `bool`. To silence this warning, use `bool` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.bool_` here.\n",
            "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:31: DeprecationWarning: `np.bool` is a deprecated alias for the builtin `bool`. To silence this warning, use `bool` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.bool_` here.\n",
            "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:32: DeprecationWarning: `np.bool` is a deprecated alias for the builtin `bool`. To silence this warning, use `bool` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.bool_` here.\n",
            "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(5091, 128, 175)\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "\n",
        "# インデックスと文字で辞書を作成\n",
        "char_indices = {}  # 文字がキーでインデックスが値\n",
        "for i, char in enumerate(chars_list):\n",
        "    char_indices[char] = i\n",
        "indices_char = {}  # インデックスがキーで文字が値\n",
        "for i, char in enumerate(chars_list):\n",
        "    indices_char[i] = char\n",
        "    \n",
        "seperator = \"。\"\n",
        "sentence_list = text.split(seperator) \n",
        "sentence_list.pop() \n",
        "sentence_list = [x+seperator for x in sentence_list]\n",
        "\n",
        "max_sentence_length = 128  # 文章の最大長さ。これより長い文章はカットされる。\n",
        "sentence_list = [sentence for sentence in sentence_list if len(sentence) <= max_sentence_length]  # 長すぎる文章のカット\n",
        "\n",
        "n_char = len(chars_list)  # 文字の種類の数\n",
        "n_sample = len(sentence_list) - 1  # サンプル数\n",
        "\n",
        "x_sentences = []  # 入力の文章\n",
        "t_sentences = []  # 正解の文章\n",
        "for i in range(n_sample):\n",
        "    x_sentences.append(sentence_list[i])\n",
        "    t_sentences.append(\"\\t\" + sentence_list[i+1] + \"\\n\")  # 正解は先頭にタブ、末尾に改行を加える\n",
        "max_length_x = max_sentence_length  # 入力文章の最大長さ\n",
        "max_length_t = max_sentence_length + 2  # 正解文章の最大長さ\n",
        "\n",
        "x_encoder = np.zeros((n_sample, max_length_x, n_char), dtype=np.bool)  # encoderへの入力\n",
        "x_decoder = np.zeros((n_sample, max_length_t, n_char), dtype=np.bool)  # decoderへの入力\n",
        "t_decoder = np.zeros((n_sample, max_length_t, n_char), dtype=np.bool)  # decoderの正解\n",
        "\n",
        "for i in range(n_sample):\n",
        "    x_sentence = x_sentences[i]\n",
        "    t_sentence = t_sentences[i]\n",
        "    for j, char in enumerate(x_sentence):\n",
        "        x_encoder[i, j, char_indices[char]] = 1  # encoderへの入力をone-hot表現で表す\n",
        "    for j, char in enumerate(t_sentence):\n",
        "        x_decoder[i, j, char_indices[char]] = 1  # decoderへの入力をone-hot表現で表す\n",
        "        if j > 0:  # 正解は入力より1つ前の時刻のものにする\n",
        "            t_decoder[i, j-1, char_indices[char]] = 1\n",
        "            \n",
        "print(x_encoder.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C5ssHXL3QgRu"
      },
      "source": [
        "## 各設定\n",
        "学習に関する各設定です。  \n",
        "「早期終了」により学習を自動ストップするので、エポック数は多めに設定します。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "collapsed": true,
        "id": "iLFhlUCXQgRv"
      },
      "outputs": [],
      "source": [
        "batch_size = 32\n",
        "epochs = 1000\n",
        "n_mid = 256  # 中間層のニューロン数"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dMvoqAfUQgRx"
      },
      "source": [
        "## 学習用モデルの構築\n",
        "学習用のSeq2Seqモデルを構築します。  \n",
        "今回は、前のセクションでより自然な文章の作成につながったGRUを使います。  \n",
        "また、入力の直後にMasking層を挟みます。\n",
        "これにより、全ての要素が0であるベクトルの入力は無視されます。  \n",
        "\n",
        "GRU層にはdropoutを設定し、ニューロンをランダムに無効にすることで過学習対策をします。  \n",
        "過学習とは、モデルが訓練データに過剰に適応してしまい、未知のデータに対して機能しなくなってしまうことです。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "SVkWnhVJQgRz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b57414ab-10a5-45da-f3aa-5b3916c2a884"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Layer gru will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
            "WARNING:tensorflow:Layer gru_1 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_1 (InputLayer)           [(None, None, 175)]  0           []                               \n",
            "                                                                                                  \n",
            " input_2 (InputLayer)           [(None, None, 175)]  0           []                               \n",
            "                                                                                                  \n",
            " masking (Masking)              (None, None, 175)    0           ['input_1[0][0]']                \n",
            "                                                                                                  \n",
            " masking_1 (Masking)            (None, None, 175)    0           ['input_2[0][0]']                \n",
            "                                                                                                  \n",
            " gru (GRU)                      [(None, 256),        332544      ['masking[0][0]']                \n",
            "                                 (None, 256)]                                                     \n",
            "                                                                                                  \n",
            " gru_1 (GRU)                    [(None, None, 256),  332544      ['masking_1[0][0]',              \n",
            "                                 (None, 256)]                     'gru[0][1]']                    \n",
            "                                                                                                  \n",
            " dense (Dense)                  (None, None, 175)    44975       ['gru_1[0][0]']                  \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 710,063\n",
            "Trainable params: 710,063\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n",
            "None\n"
          ]
        }
      ],
      "source": [
        "from keras.models import Model\n",
        "from keras.layers import Dense, GRU, Input, Masking\n",
        "\n",
        "encoder_input = Input(shape=(None, n_char))\n",
        "encoder_mask = Masking(mask_value=0)  # 全ての要素が0であるベクトルの入力は無視する\n",
        "encoder_masked = encoder_mask(encoder_input)\n",
        "encoder_lstm = GRU(n_mid, dropout=0.2, recurrent_dropout=0.2, return_state=True)  # dropoutを設定し、ニューロンをランダムに無効にする\n",
        "encoder_output, encoder_state_h = encoder_lstm(encoder_masked)\n",
        "\n",
        "decoder_input = Input(shape=(None, n_char))\n",
        "decoder_mask = Masking(mask_value=0)  # 全ての要素が0であるベクトルの入力は無視する\n",
        "decoder_masked = decoder_mask(decoder_input)\n",
        "decoder_lstm = GRU(n_mid, dropout=0.2, recurrent_dropout=0.2, return_sequences=True, return_state=True)  # dropoutを設定\n",
        "decoder_output, _ = decoder_lstm(decoder_masked, initial_state=encoder_state_h)  # encoderの状態を初期状態にする\n",
        "decoder_dense = Dense(n_char, activation='softmax')\n",
        "decoder_output = decoder_dense(decoder_output)\n",
        "\n",
        "model = Model([encoder_input, decoder_input], decoder_output)\n",
        "\n",
        "model.compile(loss=\"categorical_crossentropy\", optimizer=\"rmsprop\")\n",
        "print(model.summary())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a44BKpNXQgR1"
      },
      "source": [
        "## 学習\n",
        "構築したSeq2Seqのモデルを使って、学習を行います。  \n",
        "今回は、**早期終了**を設定します。  \n",
        "コールバックにEarlyStoppingを設定することで、学習を自動で終了させることができます。  \n",
        "誤差に改善が見られなくなってからpatianceで設定したエポック数が経過すると、学習は終了となります。  \n",
        "お手元の環境にもよりますが学習には数時間程度必要ですので、早く結果を確認したい方はpatienceの値を小さくしましょう。  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "bBZW2lqFQgR3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6343aceb-af9f-4ebc-8bb9-e9ece3b3d141"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/1000\n",
            "144/144 [==============================] - 145s 962ms/step - loss: 0.9774 - val_loss: 0.8588\n",
            "Epoch 2/1000\n",
            "144/144 [==============================] - 136s 948ms/step - loss: 0.8675 - val_loss: 0.8068\n",
            "Epoch 3/1000\n",
            "144/144 [==============================] - 135s 934ms/step - loss: 0.8271 - val_loss: 0.7800\n",
            "Epoch 4/1000\n",
            "144/144 [==============================] - 135s 937ms/step - loss: 0.8067 - val_loss: 0.7671\n",
            "Epoch 5/1000\n",
            "144/144 [==============================] - 134s 930ms/step - loss: 0.7943 - val_loss: 0.7573\n",
            "Epoch 6/1000\n",
            "144/144 [==============================] - 134s 929ms/step - loss: 0.7830 - val_loss: 0.7480\n",
            "Epoch 7/1000\n",
            "144/144 [==============================] - 134s 933ms/step - loss: 0.7746 - val_loss: 0.7494\n",
            "Epoch 8/1000\n",
            "144/144 [==============================] - 136s 942ms/step - loss: 0.7659 - val_loss: 0.7384\n",
            "Epoch 9/1000\n",
            "144/144 [==============================] - 133s 927ms/step - loss: 0.7593 - val_loss: 0.7320\n",
            "Epoch 10/1000\n",
            "144/144 [==============================] - 133s 927ms/step - loss: 0.7522 - val_loss: 0.7245\n",
            "Epoch 11/1000\n",
            "144/144 [==============================] - 133s 924ms/step - loss: 0.7465 - val_loss: 0.7203\n",
            "Epoch 12/1000\n",
            "144/144 [==============================] - 132s 914ms/step - loss: 0.7399 - val_loss: 0.7176\n",
            "Epoch 13/1000\n",
            "144/144 [==============================] - 132s 919ms/step - loss: 0.7386 - val_loss: 0.7151\n",
            "Epoch 14/1000\n",
            "144/144 [==============================] - 133s 922ms/step - loss: 0.7309 - val_loss: 0.7121\n",
            "Epoch 15/1000\n",
            "144/144 [==============================] - 132s 917ms/step - loss: 0.7232 - val_loss: 0.7064\n",
            "Epoch 16/1000\n",
            "144/144 [==============================] - 133s 921ms/step - loss: 0.7172 - val_loss: 0.7023\n",
            "Epoch 17/1000\n",
            "144/144 [==============================] - 131s 912ms/step - loss: 0.7129 - val_loss: 0.6981\n",
            "Epoch 18/1000\n",
            "144/144 [==============================] - 132s 918ms/step - loss: 0.7070 - val_loss: 0.6985\n",
            "Epoch 19/1000\n",
            "144/144 [==============================] - 133s 927ms/step - loss: 0.7018 - val_loss: 0.6922\n",
            "Epoch 20/1000\n",
            "144/144 [==============================] - 131s 913ms/step - loss: 0.6969 - val_loss: 0.6894\n",
            "Epoch 21/1000\n",
            "144/144 [==============================] - 131s 913ms/step - loss: 0.6927 - val_loss: 0.6864\n",
            "Epoch 22/1000\n",
            "144/144 [==============================] - 130s 901ms/step - loss: 0.6890 - val_loss: 0.6833\n",
            "Epoch 23/1000\n",
            "144/144 [==============================] - 132s 914ms/step - loss: 0.6839 - val_loss: 0.6846\n",
            "Epoch 24/1000\n",
            "144/144 [==============================] - 131s 907ms/step - loss: 0.6800 - val_loss: 0.6806\n",
            "Epoch 25/1000\n",
            "144/144 [==============================] - 130s 901ms/step - loss: 0.6762 - val_loss: 0.6775\n",
            "Epoch 26/1000\n",
            "144/144 [==============================] - 130s 905ms/step - loss: 0.6720 - val_loss: 0.6756\n",
            "Epoch 27/1000\n",
            "144/144 [==============================] - 130s 899ms/step - loss: 0.6683 - val_loss: 0.6746\n",
            "Epoch 28/1000\n",
            "144/144 [==============================] - 130s 906ms/step - loss: 0.6663 - val_loss: 0.6739\n",
            "Epoch 29/1000\n",
            "144/144 [==============================] - 129s 896ms/step - loss: 0.6626 - val_loss: 0.6706\n",
            "Epoch 30/1000\n",
            "144/144 [==============================] - 130s 901ms/step - loss: 0.6584 - val_loss: 0.6728\n",
            "Epoch 31/1000\n",
            "144/144 [==============================] - 130s 904ms/step - loss: 0.6553 - val_loss: 0.6686\n",
            "Epoch 32/1000\n",
            "144/144 [==============================] - 129s 898ms/step - loss: 0.6529 - val_loss: 0.6672\n",
            "Epoch 33/1000\n",
            "144/144 [==============================] - 131s 909ms/step - loss: 0.6493 - val_loss: 0.6669\n",
            "Epoch 34/1000\n",
            "144/144 [==============================] - 131s 906ms/step - loss: 0.6468 - val_loss: 0.6669\n",
            "Epoch 35/1000\n",
            "144/144 [==============================] - 130s 904ms/step - loss: 0.6445 - val_loss: 0.6627\n",
            "Epoch 36/1000\n",
            "144/144 [==============================] - 129s 895ms/step - loss: 0.6407 - val_loss: 0.6634\n",
            "Epoch 37/1000\n",
            "144/144 [==============================] - 130s 902ms/step - loss: 0.6392 - val_loss: 0.6630\n",
            "Epoch 38/1000\n",
            "144/144 [==============================] - 129s 894ms/step - loss: 0.6371 - val_loss: 0.6623\n",
            "Epoch 39/1000\n",
            "144/144 [==============================] - 130s 901ms/step - loss: 0.6345 - val_loss: 0.6611\n",
            "Epoch 40/1000\n",
            "144/144 [==============================] - 129s 893ms/step - loss: 0.6312 - val_loss: 0.6620\n",
            "Epoch 41/1000\n",
            "144/144 [==============================] - 130s 900ms/step - loss: 0.6289 - val_loss: 0.6618\n",
            "Epoch 42/1000\n",
            "144/144 [==============================] - 128s 891ms/step - loss: 0.6273 - val_loss: 0.6599\n",
            "Epoch 43/1000\n",
            "144/144 [==============================] - 129s 897ms/step - loss: 0.6257 - val_loss: 0.6576\n",
            "Epoch 44/1000\n",
            "144/144 [==============================] - 128s 892ms/step - loss: 0.6229 - val_loss: 0.6604\n",
            "Epoch 45/1000\n",
            "144/144 [==============================] - 129s 897ms/step - loss: 0.6215 - val_loss: 0.6582\n",
            "Epoch 46/1000\n",
            "144/144 [==============================] - 129s 893ms/step - loss: 0.6200 - val_loss: 0.6586\n",
            "Epoch 47/1000\n",
            "144/144 [==============================] - 129s 898ms/step - loss: 0.6183 - val_loss: 0.6598\n",
            "Epoch 48/1000\n",
            "144/144 [==============================] - 128s 890ms/step - loss: 0.6153 - val_loss: 0.6592\n",
            "Epoch 49/1000\n",
            "144/144 [==============================] - 130s 901ms/step - loss: 0.6150 - val_loss: 0.6575\n",
            "Epoch 50/1000\n",
            "144/144 [==============================] - 128s 891ms/step - loss: 0.6131 - val_loss: 0.6593\n",
            "Epoch 51/1000\n",
            "144/144 [==============================] - 129s 896ms/step - loss: 0.6106 - val_loss: 0.6576\n",
            "Epoch 52/1000\n",
            "144/144 [==============================] - 128s 891ms/step - loss: 0.6103 - val_loss: 0.6582\n",
            "Epoch 53/1000\n",
            "144/144 [==============================] - 129s 900ms/step - loss: 0.6090 - val_loss: 0.6578\n",
            "Epoch 54/1000\n",
            "144/144 [==============================] - 129s 894ms/step - loss: 0.6073 - val_loss: 0.6583\n",
            "Epoch 55/1000\n",
            "144/144 [==============================] - 130s 899ms/step - loss: 0.6066 - val_loss: 0.6580\n",
            "Epoch 56/1000\n",
            "144/144 [==============================] - 129s 896ms/step - loss: 0.6042 - val_loss: 0.6559\n",
            "Epoch 57/1000\n",
            "144/144 [==============================] - 129s 897ms/step - loss: 0.6033 - val_loss: 0.6559\n",
            "Epoch 58/1000\n",
            "144/144 [==============================] - 128s 891ms/step - loss: 0.6013 - val_loss: 0.6581\n",
            "Epoch 59/1000\n",
            "144/144 [==============================] - 128s 892ms/step - loss: 0.6004 - val_loss: 0.6591\n",
            "Epoch 60/1000\n",
            "144/144 [==============================] - 128s 887ms/step - loss: 0.5994 - val_loss: 0.6578\n",
            "Epoch 61/1000\n",
            "144/144 [==============================] - 129s 895ms/step - loss: 0.5984 - val_loss: 0.6612\n",
            "Epoch 62/1000\n",
            "144/144 [==============================] - 129s 894ms/step - loss: 0.5969 - val_loss: 0.6553\n",
            "Epoch 63/1000\n",
            "144/144 [==============================] - 128s 891ms/step - loss: 0.5948 - val_loss: 0.6548\n",
            "Epoch 64/1000\n",
            "144/144 [==============================] - 130s 900ms/step - loss: 0.5946 - val_loss: 0.6582\n",
            "Epoch 65/1000\n",
            "144/144 [==============================] - 129s 894ms/step - loss: 0.5929 - val_loss: 0.6570\n",
            "Epoch 66/1000\n",
            "144/144 [==============================] - 130s 906ms/step - loss: 0.5927 - val_loss: 0.6559\n",
            "Epoch 67/1000\n",
            "144/144 [==============================] - 130s 902ms/step - loss: 0.5913 - val_loss: 0.6570\n",
            "Epoch 68/1000\n",
            "144/144 [==============================] - 130s 905ms/step - loss: 0.5895 - val_loss: 0.6562\n",
            "Epoch 69/1000\n",
            "144/144 [==============================] - 129s 896ms/step - loss: 0.5884 - val_loss: 0.6575\n",
            "Epoch 70/1000\n",
            "144/144 [==============================] - 130s 901ms/step - loss: 0.5882 - val_loss: 0.6569\n",
            "Epoch 71/1000\n",
            "144/144 [==============================] - 130s 904ms/step - loss: 0.5866 - val_loss: 0.6597\n",
            "Epoch 72/1000\n",
            "144/144 [==============================] - 128s 889ms/step - loss: 0.5859 - val_loss: 0.6594\n",
            "Epoch 73/1000\n",
            "144/144 [==============================] - 128s 891ms/step - loss: 0.5854 - val_loss: 0.6598\n",
            "Epoch 74/1000\n",
            "144/144 [==============================] - 127s 883ms/step - loss: 0.5843 - val_loss: 0.6590\n",
            "Epoch 75/1000\n",
            "144/144 [==============================] - 128s 889ms/step - loss: 0.5836 - val_loss: 0.6564\n",
            "Epoch 76/1000\n",
            "144/144 [==============================] - 129s 893ms/step - loss: 0.5817 - val_loss: 0.6591\n",
            "Epoch 77/1000\n",
            "144/144 [==============================] - 128s 886ms/step - loss: 0.5815 - val_loss: 0.6586\n",
            "Epoch 78/1000\n",
            "144/144 [==============================] - 129s 893ms/step - loss: 0.5804 - val_loss: 0.6603\n",
            "Epoch 79/1000\n",
            "144/144 [==============================] - 127s 884ms/step - loss: 0.5793 - val_loss: 0.6609\n",
            "Epoch 80/1000\n",
            "144/144 [==============================] - 127s 883ms/step - loss: 0.5798 - val_loss: 0.6604\n",
            "Epoch 81/1000\n",
            "144/144 [==============================] - 129s 892ms/step - loss: 0.5776 - val_loss: 0.6605\n",
            "Epoch 82/1000\n",
            "144/144 [==============================] - 127s 884ms/step - loss: 0.5776 - val_loss: 0.6591\n",
            "Epoch 83/1000\n",
            "144/144 [==============================] - 128s 886ms/step - loss: 0.5764 - val_loss: 0.6605\n",
            "Epoch 84/1000\n",
            "144/144 [==============================] - 128s 886ms/step - loss: 0.5767 - val_loss: 0.6608\n",
            "Epoch 85/1000\n",
            "144/144 [==============================] - 128s 888ms/step - loss: 0.5752 - val_loss: 0.6644\n",
            "Epoch 86/1000\n",
            "144/144 [==============================] - 127s 883ms/step - loss: 0.5748 - val_loss: 0.6609\n",
            "Epoch 87/1000\n",
            "144/144 [==============================] - 128s 888ms/step - loss: 0.5736 - val_loss: 0.6612\n",
            "Epoch 88/1000\n",
            "144/144 [==============================] - 127s 880ms/step - loss: 0.5728 - val_loss: 0.6613\n",
            "Epoch 89/1000\n",
            "144/144 [==============================] - 128s 888ms/step - loss: 0.5728 - val_loss: 0.6626\n",
            "Epoch 90/1000\n",
            "144/144 [==============================] - 127s 883ms/step - loss: 0.5713 - val_loss: 0.6652\n",
            "Epoch 91/1000\n",
            "144/144 [==============================] - 127s 884ms/step - loss: 0.5708 - val_loss: 0.6630\n",
            "Epoch 92/1000\n",
            "144/144 [==============================] - 128s 892ms/step - loss: 0.5707 - val_loss: 0.6616\n",
            "Epoch 93/1000\n",
            "144/144 [==============================] - 128s 887ms/step - loss: 0.5697 - val_loss: 0.6646\n"
          ]
        }
      ],
      "source": [
        "from keras.callbacks import EarlyStopping \n",
        "\n",
        "# val_lossに改善が見られなくなってから、30エポックで学習は終了\n",
        "early_stopping = EarlyStopping(monitor=\"val_loss\", patience=30) \n",
        "\n",
        "history = model.fit([x_encoder, x_decoder], t_decoder,\n",
        "                     batch_size=batch_size,\n",
        "                     epochs=epochs,\n",
        "                     validation_split=0.1,  # 10%は検証用\n",
        "                     callbacks=[early_stopping])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2h5gj7sSQgR4"
      },
      "source": [
        "## 学習の推移\n",
        "誤差の推移を確認します。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "ZyrUTnQxQgR5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        },
        "outputId": "559219c5-e055-4483-ac30-b5ec675efe15"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "%matplotlib inline\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "loss = history.history['loss']\n",
        "val_loss = history.history['val_loss']\n",
        "\n",
        "plt.plot(np.arange(len(loss)), loss)\n",
        "plt.plot(np.arange(len(val_loss)), val_loss)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ztVtklEkQgR6"
      },
      "source": [
        "検証用データの誤差は途中で改善が止まっていますね。  \n",
        "もう少し早めに学習を終了しても良さそうです。  \n",
        "誤差の値自体はあまり小さくなっていませんが、とりあえず対話文の生成を試してみましょう。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KAh4z8g2QgR7"
      },
      "source": [
        "## 予測用モデルの構築\n",
        "学習済みのオブジェクトから、encoder、decoderのモデルを個別に構築します。    \n",
        "encoderは入力を受け取って状態を返し、decoderは入力と状態を受け取って出力と状態を返すようにします。  \n",
        "構築したモデルは、後のレクチャーで使えるように保存しておきます。  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "Z4fqCWnRQgR7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "429fdc6e-3309-490b-ab09-07539febd504"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
            "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
          ]
        }
      ],
      "source": [
        "# encoderのモデル\n",
        "encoder_model = Model(encoder_input, encoder_state_h)\n",
        "\n",
        "# decoderのモデル\n",
        "decoder_state_in_h = Input(shape=(n_mid,))\n",
        "decoder_state_in = [decoder_state_in_h]\n",
        "\n",
        "decoder_output, decoder_state_h = decoder_lstm(decoder_input,\n",
        "                                               initial_state=decoder_state_in_h)\n",
        "decoder_output = decoder_dense(decoder_output)\n",
        "\n",
        "decoder_model = Model([decoder_input] + decoder_state_in,\n",
        "                      [decoder_output, decoder_state_h])\n",
        "\n",
        "# モデルの保存\n",
        "encoder_model.save('encoder_model.h5')\n",
        "decoder_model.save('decoder_model.h5')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CMVaa6NXQgR-"
      },
      "source": [
        "## 返答作成用の関数\n",
        "入力を出力に変換し、返答を作成するための関数を設定します。  \n",
        "decoderでは、各時刻ごとに予測を行い、出力と状態を次の時刻に渡します。  \n",
        "decoderの出力を確率として捉え、その確率に従ってサンプリングを行うので実行するたびにやや異なる文章が生成されます。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "collapsed": true,
        "id": "2yl1LHBCQgR-"
      },
      "outputs": [],
      "source": [
        "def respond(input_data, beta=5):\n",
        "    state_value = encoder_model.predict(input_data)\n",
        "    y_decoder = np.zeros((1, 1, n_char))  # decoderの出力を格納する配列\n",
        "    y_decoder[0][0][char_indices[\"\\t\"]] = 1  # decoderの最初の入力はタブ。one-hot表現にする。\n",
        "\n",
        "    respond_sentence = \"\"  # 返答の文字列\n",
        "    while True:\n",
        "        y, h = decoder_model.predict([y_decoder, state_value])\n",
        "        p_power = y[0][0] ** beta  # 確率分布の調整\n",
        "        next_index = np.random.choice(len(p_power), p=p_power/np.sum(p_power)) \n",
        "        next_char = indices_char[next_index]  # 次の文字\n",
        "\n",
        "        if (next_char == \"\\n\" or len(respond_sentence) >= max_length_x):\n",
        "            break  # 次の文字が改行のとき、もしくは最大文字数を超えたときは終了\n",
        "            \n",
        "        respond_sentence += next_char\n",
        "        y_decoder = np.zeros((1, 1, n_char))  # 次の時刻の入力\n",
        "        y_decoder[0][0][next_index] = 1\n",
        "\n",
        "        state_value = h  # 次の時刻の状態\n",
        "\n",
        "    return respond_sentence"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2RSuhjErQgR_"
      },
      "source": [
        "## 動作の確認\n",
        "訓練データの最初の100文を使って、どのような返答が返ってくるかを確かめます。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "bET5s6tWQgSA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ddcec178-8423-45a9-c2af-deaaee8962f8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input: ではみなさんは、そういうふうにかわだといわれたり、ちちのながれたあとだといわれたりしていたこのぼんやりとしろいものがほんとうはなにかごしょうちですか。\n",
            "Response: せんせいはまたいいました。\n",
            "\n",
            "Input: せんせいは、こくばんにつるしたおおきなくろいせいざのずの、うえからしたへしろくけぶったぎんがおびのようなところをさしながら、みんなにとをかけました。\n",
            "Response: といいました。\n",
            "\n",
            "Input: カムパネルラがてをあげました。\n",
            "Response: げん、ちいさなほんとうにきているのでした。\n",
            "\n",
            "Input: それからしごにんてをあげました。\n",
            "Response: そしてえんとしたのです。\n",
            "\n",
            "Input: ジョバンニもてをあげようとして、いそいでそのままやめました。\n",
            "Response: するとそのしたのは、あかいはながさけびました。\n",
            "\n",
            "Input: たしかにあれがみんなほしだと、いつかざっしでよんだのでしたが、このごろはジョバンニはまるでまいにちきょうしつでもねむく、ほんをよむひまもよむほんもないので、なんだかどんなこともよくわからないというきもちがするのでした。\n",
            "Response: ところがそのとき、すこしおおきなこえで、あかいしゃしにいってしまいました。\n",
            "\n",
            "Input: ところがせんせいははやくもそれをみつけけたのでした。\n",
            "Response: みんなはそのちいさなこどものかたちになって、またおもしろいくものをみていました。\n",
            "\n",
            "Input: ジョバンニさん。\n",
            "Response: ぼくたちはいっしょうけんいのちいさなこえがあるいているんだ。\n",
            "\n",
            "Input: あなたはわかっているのでしょう。\n",
            "Response: それはぼくはもうしました。\n",
            "\n",
            "Input: ジョバンニはせいよくたちあがりましたが、たってみるともうはっきりとそれをこたえることができないのでした。\n",
            "Response: そのとき、ぼくはそのとき、すこしおおきなこえで、すっかりしたくのように、すこしおおきなこえで、あのこどものかわのみずをはいていました。\n",
            "\n",
            "Input: ザネリがまえのせきからふりかえって、ジョバンニをみてくすっとわらいました。\n",
            "Response: ジョバンニは、それをみつめていたのです。\n",
            "\n",
            "Input: ジョバンニはもうどぎまぎしてまっあかになってしまいました。\n",
            "Response: なんだ、あんまりおもしろい。\n",
            "\n",
            "Input: せんせいがまたいいました。\n",
            "Response: といいました。\n",
            "\n",
            "Input: おおきなぼうえんきょうでぎんがをよっくしらべるとぎんがはだいたいなんでしょう。\n",
            "Response: いいか。\n",
            "\n",
            "Input: やっぱりほしだとジョバンニはおもいましたがこんどもすぐにこたえることができませんでした。\n",
            "Response: せんせい、それはこんなにひゃくはこをかけるときは、あかいはながさけびました。\n",
            "\n",
            "Input: せんせいはしばらくこまったようすでしたが、めをカムパネルラのほうへむけて、ではカムパネルラさん。\n",
            "Response: といいました。\n",
            "\n",
            "Input: となざしました。\n",
            "Response: するとそのしたのは、しゅじんは、またおとこのこがいいました。\n",
            "\n",
            "Input: するとあんなにげんきにてをあげたカムパネルラが、やはりもじもじたちあったままやはりこたえができませんでした。\n",
            "Response: おかあさんは、それをうけとっているのでした。\n",
            "\n",
            "Input: せんせいはいがいなようにしばらくじっとカムパネルラをみていましたが、いそいででは。\n",
            "Response: といいました。\n",
            "\n",
            "Input: よし。\n",
            "Response: イーハトーヴのかんぱんのしたにんのしろいいわのかんがえるのです。\n",
            "\n",
            "Input: といいながら、じぶんでせいずをさしました。\n",
            "Response: それでもそのまんなかにはかせはこんどはあんまりそのこどものじょしゅがやっぱりでていました。\n",
            "\n",
            "Input: このぼんやりとしろいぎんがをおおきないいぼうえんきょうでみますと、もうたくさんのちいさなほしにみえるのです。\n",
            "Response: ジョバンニは、もうどこからいっしょにいいました。\n",
            "\n",
            "Input: ジョバンニさんそうでしょう。\n",
            "Response: ぼくはそこをみると、すこしおおきなこえですか。\n",
            "\n",
            "Input: ジョバンニはまっあかになってうなずきました。\n",
            "Response: さあ、こんなことをいいました。\n",
            "\n",
            "Input: けれどもいつかジョバンニのめのなかにはなみだがいっぱいになりました。\n",
            "Response: こういちは、またさぶろうはすこしおおきなこえでした。\n",
            "\n",
            "Input: そうだぼくはしっていたのだ、もちろんカムパネルラもしっている、それはいつかカムパネルラのおとうさんのはかせのうちでカムパネルラといっしょによんだざっしのなかにあったのだ。\n",
            "Response: それはぼくはもうあんまりおかしいよ。\n",
            "\n",
            "Input: それどこでなくカムパネルラは、そのざっしをよむと、すぐおとうさんのしょさいからきょきなほんをもってきて、ぎんがというところをひろげ、まっくろなぺーじいっぱいにしろいてんてんのあるうつくしいしゃしんをふたりでいつまでもみたのでした。\n",
            "Response: それからそのにんのところへいってしまいました。\n",
            "\n",
            "Input: せんせいはまたいいました。\n",
            "Response: おまえたちはぼくたちのここではなんだ。\n",
            "\n",
            "Input: ですからもしもこのてんのかわがほんとうにかわだとかんがえるなら、そのひとつひとつのちいさなほしはみんなそのかわのそこのすなやじゃりのつぶにもあたるわけです。\n",
            "Response: ブドリはそのときをして、いちろうはまたさぶろうはまたあおいろをみていました。\n",
            "\n",
            "Input: またこれをきょきなちちのながれとかんがえるならもっとてんのかわとよくにています。\n",
            "Response: それでもそのまんなかにはいってきて、それから？それから？それから？あとはどうしてもうしました。\n",
            "\n",
            "Input: つまりそのほしはみな、ちちのなかにまるでこまかにうかんでいるあぶらあぶらのたまにもあたるのです。\n",
            "Response: そしてそのつぎのにちは、あのあかいはなをつかまえて、しばらくあったのです。\n",
            "\n",
            "Input: そんならなにがそのかわのみずにあたるかといいますと、それはしんくうというひかりをあるはやさでつたえるもので、たいようやちきゅうもやっぱりそのなかにうかんでいるのです。\n",
            "Response: そしてそのとき、すこしおおきなこえで、あんまりおかしいことをいって、いままでいっていました。\n",
            "\n",
            "Input: つまりはわたしどももてんのかわのみずのなかにすんでいるわけです。\n",
            "Response: ブドリは、おおきなこえで、あのこどものかいをひろげて、こんどはおもわずわらいました。\n",
            "\n",
            "Input: そしてそのてんのかわのみずのなかからしほうをみると、ちょうどみずがふかいほどあおくみえるように、てんのかわのそこのふかくとおいところほどほしがたくさんつどってみえしたがってしろくぼんやりみえるのです。\n",
            "Response: そしてそのおとこのこがいいました。\n",
            "\n",
            "Input: このもけいをごらんなさい。\n",
            "Response: せいねんはいいました。\n",
            "\n",
            "Input: せんせいはなかにたくさんひかるすなのつぶのいっったおおきなりょうめんのとつレンズをさしました。\n",
            "Response: いちろうはまたさぶろうはすこしおしました。\n",
            "\n",
            "Input: てんのかわのかたちはちょうどこんななのです。\n",
            "Response: こういちはいきなりあたまをみました。\n",
            "\n",
            "Input: このいちいちのひかるつぶがみんなわたしどものたいようとおなじようにじぶんでひかっているほしだとかんがえます。\n",
            "Response: そしてそのとき、おとうさんが、おおきなこえで、あのこどものかいをひろげて、しゃしょうのようになって、あおいかんのあしをかけて、いいました。\n",
            "\n",
            "Input: わたしどものたいようがこのほぼなかごろにあってちきゅうがそのすぐちかくにあるとします。\n",
            "Response: ホモイは、それをみつめて、あかいしゃしんしたのです。\n",
            "\n",
            "Input: みなさんはよるにこのまんなかにたってこのレンズのなかをみまわすとしてごらんなさい。\n",
            "Response: おまえたちはこんどはあんまりおくれ。\n",
            "\n",
            "Input: こっちのかたはレンズがうすいのでわずかのひかるつぶすなわちほししかみえないのでしょう。\n",
            "Response: せいねんはおまえたちのほうへまっていました。\n",
            "\n",
            "Input: こっちやこっちのかたはガラスがあついので、ひかるつぶすなわちほしがたくさんみえそのとおいのはぼうっとしろくみえるというこれがつまりきょうのぎんがのせつなのです。\n",
            "Response: ああ、あんまりいくらもうしました。\n",
            "\n",
            "Input: そんならこのレンズのおおきさがどれくらあるかまたそのなかのさまざまのほしについてはもうじかんですからこのつぎのりかのじかんにおはなします。\n",
            "Response: といいました。\n",
            "\n",
            "Input: ではこんにちはそのぎんがのおまつりなのですからみなさんはそとへでてよくそらをごらんなさい。\n",
            "Response: なんだかあったんだ。\n",
            "\n",
            "Input: ではここまでです。\n",
            "Response: せんせい、このおとこは、なんだか、まるであかくしているのでした。\n",
            "\n",
            "Input: ほんやノートをおしまいなさい。\n",
            "Response: それでもそのときはすこしおおきなこえで、いきなりおかしいようになっていました。\n",
            "\n",
            "Input: そしてきょうしつなかはしばらくつくえのふたをあけたりしめたりほんをおもねたりするおとがいっぱいでしたがまもなくみんなはきちんとたってれいをするときょうしつをでました。\n",
            "Response: そしてしまいました。\n",
            "\n",
            "Input: に、かっぱんところジョバンニががっこうのもんをでるとき、おなじくのしちはちにんはいえへかえらずカムパネルラをまんなかにしてこうていのすみのさくらのきのところにあつまっていました。\n",
            "Response: それでもそのまんなかにはいってきました。\n",
            "\n",
            "Input: それはこんやのほしまつりにあおいあかりをこしらえてかわへながすからすうりをとりにいくそうだんらしかったのです。\n",
            "Response: それでもそのときは、すこしいちろうがあったのです。\n",
            "\n",
            "Input: けれどもジョバンニはてをおおきくふってどしどしがっこうのもんをでてきました。\n",
            "Response: そしてしまいました。\n",
            "\n",
            "Input: するとまちのいえいえではこんやのぎんがのまつりにいちいのはのたまをつるしたりひのきのえだにあかりをつけたりいろいろしたくをしているのでした。\n",
            "Response: それはどうしてもいいんだ。\n",
            "\n",
            "Input: いえへはかえらずジョバンニがまちをみつまってあるおおきなかっぱんところにはいってすぐいりぐちのけいさんだいにいただぶだぶのしろいシャツをきたにんにおじぎをしてジョバンニはくつをぬいでのぼりますと、つきあたりのおおきなとびらをあけました。\n",
            "Response: それからあのこどものはなしをとりました。\n",
            "\n",
            "Input: なかにはまだひるなのにでんとうがついてたくさんのりんてんうつわがばたりばたりとまわり、きれであたまをしばったりラムプシェードをかけたりしたにんたちが、なにかうたうようによんだりかぞえたりしながらたくさんはたらいていりました。\n",
            "Response: それでもそれはどうしてもいいました。\n",
            "\n",
            "Input: ジョバンニはすぐいりぐちからさんばんめのたかいすぐるこにすわったにんのところへいっておじぎをしました。\n",
            "Response: そのときぼくたちのなかでは、おまえたちのこのこはせいさくをみているのでした。\n",
            "\n",
            "Input: そのにんはしばらくたなをさがしてから、これだけひろっていけるかね。\n",
            "Response: そうだ。\n",
            "\n",
            "Input: といいながら、いちまいのかみきれをわたしました。\n",
            "Response: そこでカンかえるはまたさぶろうはまたにちぱちぱちぱちぱちぱちぱちぱちぱちぱちぱちぱちぱちぱちぱちぱちぱちぱちぱちぱちぱちぱちぱちぱちぱちぱちぱちぱちぱちぱちぱちぱちぱちぱちぱちぱちぱちぱちぱちぱちぱちぱちぱちぱちぱちぱちぱちぱちぱちぱちぱちぱちぱちぱちぱち\n",
            "\n",
            "Input: ジョバンニはそのにんのすぐるこのあしもとからひとつのちいさなひらたいはこをとりだしてむうのでんとうのたくさんついた、たてかけてあるかべのすみのところへしゃがみこむとちいさなピンセットでまるであわつぶぐらいのかつじをつぎからつぎとひろいはじめました。\n",
            "Response: そしてあのときのにんたちは、このにんのしゅじんは、まるであかいしゃしんしゃしたいのです。\n",
            "\n",
            "Input: あおいむねあてをしたにんがジョバンニのうしろをとうりながら、よう、むしめがねくん、おはやう。\n",
            "Response: といいました。\n",
            "\n",
            "Input: といいますと、ちかくのしごにんのにんたちがこえもたてずこっちもむかずにれいくわらいました。\n",
            "Response: そしてそのとき、すこしおおきなこえで、あのこどものはなしをしょうめんにいってしまいました。\n",
            "\n",
            "Input: ジョバンニはなにべんもめをぬぐいながらかつじをだんだんひろいました。\n",
            "Response: そのとき、みんなは、またいっぽんのしゅじんがいいました。\n",
            "\n",
            "Input: ろくときがうってしばらくたったころ、ジョバンニはひろったかつじをいっぱいにいれたひらたいはこをもういちどてにもったかみきれとひきあわせてから、さっきのすぐるこのにんへもってきました。\n",
            "Response: そしてしまいました。\n",
            "\n",
            "Input: そのにんはだまってそれをうけとってかすかにうなずきました。\n",
            "Response: ブドリは、どこかですからないていました。\n",
            "\n",
            "Input: ジョバンニはおじぎをするととびらをあけてさっきのけいさんだいのところにきました。\n",
            "Response: そしてしまいました。\n",
            "\n",
            "Input: するとさっきのしろふくをきたにんがやっぱりだまってちいさなぎんかをひとつジョバンニにわたしました。\n",
            "Response: ホモイはそれをみつめていました。\n",
            "\n",
            "Input: ジョバンニはにわかにかおいろがよくなっていせいよくおじぎをするとだいのしたにおいたかばんをもっておもてへとびだしました。\n",
            "Response: そのとき、それからそのこのこのふたつのおおきなこえで、あかいにんが、すこしおおきなやつのなかに、あかいしゃしに、しろいせいのたかいところをみていました。\n",
            "\n",
            "Input: それからげんきよくくちぶえをふきながらパンやへよってパンのかいをひとつとかくざとうをひとふくろかいますといちもくさんにはしりだしました。\n",
            "Response: それから、すこしおおきなあおいろをひろげて、こんどはまたさぶろうはきょうきょうのほうへまっていました。\n",
            "\n",
            "Input: さん、いえジョバンニがせいよくかえってきたのは、あるうらまちのちいさないえでした。\n",
            "Response: それはもういちぺんにいってしまいました。\n",
            "\n",
            "Input: そのみつならんだいりぐちのいちばんひだりがわにはからばこにむらさきいろのケールやアスパラガスがうえてあってちいさなふたつのまどにはにちおおいがくだりたままになっていました。\n",
            "Response: そしてそのおとこは、なにかおおきなかえりです。\n",
            "\n",
            "Input: おかあさん。\n",
            "Response: これはもういちぺんにかいてあるんだ。\n",
            "\n",
            "Input: いまかえったよ。\n",
            "Response: いいね。\n",
            "\n",
            "Input: ぐあいわるくなかったの。\n",
            "Response: ジョバンニは、それから、このまえにはいってきました。\n",
            "\n",
            "Input: ジョバンニはくつをぬぎながらいいました。\n",
            "Response: ぼくはそのことをいっているんだ。\n",
            "\n",
            "Input: ああ、ジョバンニ、おしごとがひどかったろう。\n",
            "Response: ああ、こんどはぼくたちのほうへいってるんだ。\n",
            "\n",
            "Input: こんにちはすずしくてね。\n",
            "Response: いちろうがまたさぶろうはまたあおいろをひろっていました。\n",
            "\n",
            "Input: わたしはずうっとぐあいがいいよ。\n",
            "Response: ところがありません。\n",
            "\n",
            "Input: ジョバンニはげんかんをあっていきますとジョバンニのおかあさんがすぐいりぐちのしつにしろいはばをおおってねんでいたのでした。\n",
            "Response: そのときあしのきたのは、あかいのひがしのようになって、あのおとこのこをかけて、いきなり、こんなことをいいました。\n",
            "\n",
            "Input: ジョバンニはまどをあけました。\n",
            "Response: どうしてもうしました。\n",
            "\n",
            "Input: おかあさん。\n",
            "Response: いいか。\n",
            "\n",
            "Input: こんにちはかくざとうをかってきたよ。\n",
            "Response: ああ、こういちはいいました。\n",
            "\n",
            "Input: ぎゅうにゅうにいれてあげようとおもって。\n",
            "Response: ああ、こんどはぼくたちのほうへいってるんだ。\n",
            "\n",
            "Input: ああ、おまえさきにおあがり。\n",
            "Response: あしたのはらのかわのみずをはいているのです。\n",
            "\n",
            "Input: あたしはまだほしくないんだから。\n",
            "Response: おかあさん。\n",
            "\n",
            "Input: おかあさん。\n",
            "Response: ぼくはもういちぺんにいったんだ。\n",
            "\n",
            "Input: ねえさんはいつかえったの。\n",
            "Response: ひらりとりのにんが、こんなことをいいました。\n",
            "\n",
            "Input: ああさんじころかえったよ。\n",
            "Response: おかあさん。\n",
            "\n",
            "Input: みんなそこらをしてくれてね。\n",
            "Response: またさぶろうはすこしいきました。\n",
            "\n",
            "Input: おかあさんのぎゅうにゅうはきていないんだろうか。\n",
            "Response: ぼくはそこでこういちはいました。\n",
            "\n",
            "Input: こなかったろうかねえ。\n",
            "Response: ぼくはもういちばんはいいました。\n",
            "\n",
            "Input: ぼくいってとってこよう。\n",
            "Response: そしてしまいました。\n",
            "\n",
            "Input: あああたしはゆっくりでいいんだからおまえさきにおあがり、ねえさんがね、トマトでなにかこしらえてそこへおいていったよ。\n",
            "Response: ところがそのときはすこしあるいているようになりました。\n",
            "\n",
            "Input: ではぼくたべよう。\n",
            "Response: ジョバンニは、それをみつめて、ちょうどしました。\n",
            "\n",
            "Input: ジョバンニはまどのところからトマトのさらをとってパンといっしょにしばらくむしゃむしゃたべました。\n",
            "Response: そのときぼくは、あんなにんがあるいているんだ。\n",
            "\n",
            "Input: ねえおかあさん。\n",
            "Response: ぼくはそこですからない。\n",
            "\n",
            "Input: ぼくおとうさんはきっとかんもなくかえってくるとおもうよ。\n",
            "Response: ああ、あかいはいってきた。\n",
            "\n",
            "Input: あああたしもそうおもう。\n",
            "Response: けれどもそれから？それから？それから？それから？あとは？それから？それから？それから？それから？それから？それから？それから？それから？それから？あとはどうだい。\n",
            "\n",
            "Input: けれどもおまえはどうしてそうおもうの。\n",
            "Response: それから？それから？それから？それから？それから？それから？それから？それから？あとは？それから？それから？それから？それから？それから？それから？それから？それから？それから？それから？それから？それから？それから？それから？それから？それから？それから\n",
            "\n",
            "Input: だってけさのしんぶんにこんねんはきたのほうのりょうはだいへんよかったとかいてあったよ。\n",
            "Response: ぼくはそこでおいで。\n",
            "\n",
            "Input: ああだけどねえ、おとうさんはりょうへでていないかもしれない。\n",
            "Response: いちろうがまたさぶろうはすこしおおきなかえりをみました。\n",
            "\n",
            "Input: きっとでているよ。\n",
            "Response: そうだ。\n",
            "\n",
            "Input: おとうさんがかんごくへいるようなそんなわるいことをしたはずがないんだ。\n",
            "Response: おかあさんがいいました。\n",
            "\n"
          ]
        }
      ],
      "source": [
        "for i in range(100):  \n",
        "    x_in = x_encoder[i:i+1]  # 入力\n",
        "    responce = respond(x_in)  # 返答\n",
        "    print(\"Input:\", x_sentences[i])\n",
        "    print(\"Response:\", responce)\n",
        "    print()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cfPrKt39QgSB"
      },
      "source": [
        "小説内の文章に対して、しばしばそれらしい返答ができていますね。  \n",
        "中には、意味がよく分からない返答もあります。\n",
        "\n",
        "次のレクチャーでは、小説外の文章に対してモデルがどのように返答するのか検証していきます。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yZUYmQ63QgSC"
      },
      "source": [
        "## 課題\n",
        "上記のセルでbetaの値を変更し、返答の文章がどのように変化するか確かめてみましょう。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "mV87AS4vQgSC"
      },
      "outputs": [],
      "source": [
        ""
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.5.4"
    },
    "colab": {
      "name": "learn_dialogue.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}