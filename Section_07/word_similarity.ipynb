{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/alicelindel3/nlp/blob/main/Section_07/word_similarity.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i0147F069nlw"
      },
      "source": [
        "# 単語の類似度\n",
        "word2vecを用いて、2つの単語の類似度を求めます。"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip list"
      ],
      "metadata": {
        "id": "D6Q33X_F9qqY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j1cNNybx9nl0"
      },
      "source": [
        "## データの読み込み、及びword2vecによる学習\n",
        "前回と同様に、データの読み込み及びword2vecによる学習を行います。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3EdGYxG-9nl1"
      },
      "outputs": [],
      "source": [
        "import pickle\n",
        "from gensim.models import word2vec\n",
        "\n",
        "with open('wagahai_words.pickle', mode='rb') as f:\n",
        "    wagahai_words = pickle.load(f)\n",
        "\n",
        "print(wagahai_words[:10])\n",
        "\n",
        "# size : 中間層のニューロン数\n",
        "# min_count : この値以下の出現回数の単語を無視\n",
        "# window : 対象単語を中心とした前後の単語数\n",
        "# iter : epochs数\n",
        "# sg : CBOWを使うかskip-gramを使うか 0:CBOW 1:skip-gram\n",
        "model = word2vec.Word2Vec(wagahai_words,\n",
        "                          size=100, \n",
        "                          min_count=5,\n",
        "                          window=5,\n",
        "                          iter=20,\n",
        "                          sg = 0)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rLgQ-HIy9nl6"
      },
      "source": [
        "## 類似度の高い単語\n",
        "ある単語と類似度の高い単語を表示します。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5HpSHsEx9nl7"
      },
      "outputs": [],
      "source": [
        "print(model.wv.most_similar(\"猫\"))  # 最も似ている単語"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1kfplWOn9nl8"
      },
      "source": [
        "学習データが小さいため、今回はあまり興味深い結果にはなりません。  \n",
        "興味のある方は、他の小説をなどをコーパスに加え、学習データを大きくしてみましょう。  \n",
        "\n",
        "なお、単語の類似度は以下の式で表されるコサイン類似度で計算しています。  \n",
        "ベクトル$\\vec{a}=(a_1,a_2,\\cdots, a_n)$、$\\vec{b}=(b_1,b_2,\\cdots, b_n)$として、\n",
        "$$\\frac{a_1b_1+a_2b_2+\\cdots + a_nb_n}{\\sqrt{a_1^2+a_2^2+\\cdots+a_n^2}\\sqrt{b_1^2+b_2^2+\\cdots+b_n^2}}$$\n",
        "\n",
        "試しに、コサイン類似度を計算してみましょう。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6IFzuhp89nl9"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "\n",
        "a = model.wv.__getitem__(\"猫\")\n",
        "b = model.wv.__getitem__(\"人間\")\n",
        "cos_sim = np.dot(a, b) / np.linalg.norm(a) / np.linalg.norm(b)  # linalg.normで二乗和の平方根（ノルム）を計算\n",
        "print(cos_sim)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Gxj-Zaz49nl-"
      },
      "source": [
        "猫と人間の類似度は、先ほどの結果と同じになりました。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dGFagrqM9nl_"
      },
      "source": [
        "## 課題:\n",
        "「名前」という単語と類似度の高い単語を表示してみましょう。  \n",
        "また、最も類似度が高い単語とのコサイン類似度を計算してみましょう。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0-BxPHCk9nmA"
      },
      "outputs": [],
      "source": [
        "print(model.wv.most_similar(\"名前\"))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "a = model.wv.__getitem__(\"名前\")\n",
        "b = model.wv.__getitem__(\"変り\")\n",
        "cos_sim = np.dot(a, b) / np.linalg.norm(a) / np.linalg.norm(b)  # linalg.normで二乗和の平方根（ノルム）を計算\n",
        "print(cos_sim)"
      ],
      "metadata": {
        "id": "d7qgOxtJ_mHG"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.12"
    },
    "colab": {
      "name": "word_similarity.ipynb",
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}